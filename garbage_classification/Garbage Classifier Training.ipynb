{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.optim import Adam\n",
    "from dataloader import *\n",
    "from torch.utils.data.dataset import random_split\n",
    "from training_utils import *\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the dataset and perform splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trashset = TrashNetDataset(\"trashnet/data/dataset-resized\")\n",
    "valsize = int(len(trashset) * 0.1)\n",
    "trainsize = int(len(trashset) * 0.8)\n",
    "testsize = len(trashset) - valsize - trainsize\n",
    "torch.manual_seed(0) # Ensure dataset is randomly split the same way each time\n",
    "train_dataset, val_dataset, test_dataset = random_split(trashset, [trainsize, valsize, testsize])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating transformer to perform data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "#     transforms.Pad(300, padding_mode='reflect'),\n",
    "#     transforms.RandomRotation(20,expand=True),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing transformer (running is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x, y = trashset[0]\n",
    "print(\"Before Transform Shape:\", x.shape)\n",
    "plot(x, y)\n",
    "xT = transform(x)\n",
    "print(\"After Transform Shape:\", xT.shape)\n",
    "plot(xT, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualizing some samples (running is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dataloader))\n",
    "transform_batch(x, transform)\n",
    "for ix in range(len(x)):\n",
    "    plot(x[ix], y[ix].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initializing the model and optomizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with desired network\n",
    "from torchvision.models.resnet import *\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, len(CLASSES), bias=True)\n",
    "model.fc.requires_grad = True\n",
    "model.device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    model.device = 'cuda'\n",
    "model = model.to(model.device)\n",
    "opt = Adam(model.parameters(), lr=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "total_acc = []\n",
    "total_learning_rate = []\n",
    "total_batch_size = []\n",
    "total_train_full = []\n",
    "num_epochs = 0\n",
    "epochs_per_run = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model & fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to start a new training epoch\n",
    "num_epochs += epochs_per_run\n",
    "losses, acc = train_model(model, train_dataloader, val_dataloader, opt, epochs_per_run, transform=transform)\n",
    "total_loss += losses\n",
    "total_acc += acc\n",
    "total_learning_rate += [opt.defaults['lr']] * len(acc)\n",
    "total_batch_size += [train_dataloader.batch_size] * len(acc)\n",
    "train_full = True\n",
    "for param in model.parameters():\n",
    "    train_full |= param.requires_grad\n",
    "total_train_full += [train_full] * len(acc)\n",
    "\n",
    "fig = plt.figure(figsize=(20,3))\n",
    "plt.subplot(141)\n",
    "plt.plot(total_loss)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.subplot(142)\n",
    "plt.plot(total_acc)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.subplot(143)\n",
    "plt.plot(total_batch_size)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Batch Size\")\n",
    "plt.subplot(144)\n",
    "plt.plot(torch.log10(torch.tensor(total_learning_rate)))\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to fine tune hyperparameters in between epochs\n",
    "opt = Adam(model.parameters(), lr=0.0001)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc = evaluate(model, test_dataloader)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the weights and training metadata. Make sure to set the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"test\"\n",
    "\n",
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "if not os.path.isdir(\"models/\" + model_name):\n",
    "    os.mkdir(\"models/\" + model_name)\n",
    "torch.save(model.state_dict(), \"models/\" + model_name + \"/weights.checkpoint\")\n",
    "torch.save(model.state_dict(), \"models/\" + model_name + \"/weights.checkpoint\")\n",
    "training_metadata = {\"total_loss\" : total_loss, \"total_acc\" : total_acc, \"total_learning_rate\" : total_learning_rate, \"total_batch_size\" : total_batch_size, \"total_train_full\" : total_train_full, \"num_epochs\" : num_epochs}\n",
    "pickle_out = open(\"models/\" + model_name + \"/training_metadata.pickle\",\"wb\")\n",
    "pickle.dump(training_metadata, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

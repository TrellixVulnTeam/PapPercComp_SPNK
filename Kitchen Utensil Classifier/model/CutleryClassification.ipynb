{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CutleryClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI7YeDO8PvOi",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import Statements and Constant Declarations (e.g. config variables, paths)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0JXGY5CPrDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from typing import Type, Tuple\n",
        "from abc import ABC\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "STORAGE_DIR = '/content/drive/My Drive/MyCNN'\n",
        "STORAGE_MODEL = os.path.join(STORAGE_DIR, 'best-model')\n",
        "STORAGE_MODEL_TEMP = STORAGE_MODEL + '.tmp'\n",
        "STORAGE_ONNX = os.path.join(STORAGE_DIR, \"kitchen_classifier.onnx\")\n",
        "\n",
        "DATA_DIR = '/content/utensil-images'\n",
        "BATCH_SIZE = 16\n",
        "INPUT_SIZE = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNNJr_jM7Swc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eePLkYZrNzU4",
        "colab_type": "text"
      },
      "source": [
        "# 2. Retrieve data from github repository\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i217Muo-RVTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# git-lfs is needed for the dataset\n",
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "KEEP_FREQ = 2\n",
        "\n",
        "def move_files(path: str, base_dir: str, keep_frequency: int = 0) -> None:\n",
        "    base_in = os.path.join(base_dir, path)\n",
        "\n",
        "    drop_counter = 0\n",
        "    for file_name in os.listdir(base_in):\n",
        "        if file_name == 'test':\n",
        "            target_dir = os.path.join(base_dir, 'validation', path)\n",
        "            print(target_dir)\n",
        "            shutil.rmtree(target_dir, ignore_errors=True)\n",
        "            shutil.move(os.path.join(base_in, file_name),\n",
        "                            target_dir)\n",
        "            continue\n",
        "        \n",
        "        if keep_frequency:\n",
        "            drop_counter += 1\n",
        "            if drop_counter != keep_frequency:\n",
        "                continue\n",
        "\n",
        "        drop_counter = 0\n",
        "        target_dir = os.path.join(base_dir, 'train', path)\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        shutil.move(os.path.join(base_dir, path, file_name),\n",
        "                        os.path.join(target_dir, file_name))\n",
        "    \n",
        "    return\n",
        "\n",
        "    for file_name in os.listdir(base_in):\n",
        "        if file_name == 'test':\n",
        "            target = os.path.join(base_dir, 'test', path)\n",
        "            print(target)\n",
        "            shutil.rmtree(target, ignore_errors=True)\n",
        "            shutil.move(os.path.join(base_in, file_name),\n",
        "                        target)\n",
        "            continue\n",
        "        rand = random.random()\n",
        "        total_prob = 0\n",
        "        for prob, target in probabilities.items():\n",
        "            target_dir = os.path.join(base_dir, target, path)\n",
        "            total_prob += prob\n",
        "            if rand < total_prob:\n",
        "                target_dir = os.path.join(base_dir, target, path)\n",
        "                shutil.move(os.path.join(base_dir, path, file_name),\n",
        "                            os.path.join(base_dir, target_dir, file_name))\n",
        "                break\n",
        "\n",
        "def partition_image_data(path: str) -> int:\n",
        "    dirs = [f.name for f in os.scandir(path) if f.is_dir()]\n",
        "    print(dirs)\n",
        "\n",
        "    for directory in dirs:\n",
        "      move_files(directory, path, KEEP_FREQ)\n",
        "    \n",
        "    [shutil.rmtree(os.path.join(path, directory)) for directory in dirs]\n",
        "    \n",
        "    return len(dirs)\n",
        "\n",
        "!rm -rf kitchen-utensils/\n",
        "!git clone https://github.com/BeeblebroxIV/kitchen-utensils.git\n",
        "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
        "\n",
        "os.mkdir(DATA_DIR)\n",
        "!tar -xf kitchen-utensils/kitchen-utensils.tar.gz --directory \"/content/utensil-images\"\n",
        "NUM_CLASSES = partition_image_data(DATA_DIR)\n",
        "!tar -xf kitchen-utensils/background-test.tar.gz --directory \"/content/utensil-images\"\n",
        "!tar -xf kitchen-utensils/distance-test.tar.gz --directory \"/content/utensil-images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhWSqltcOG5Q",
        "colab_type": "text"
      },
      "source": [
        "# 3. Setup dataloaders as well as functions for training / visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6zbYx7Uiu-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Precomputed for dataset\n",
        "mean = [0.4399, 0.4211, 0.3609]\n",
        "std = [0.1220, 0.1210, 0.1228]\n",
        "\n",
        "data_transforms = {}\n",
        "\n",
        "for f in os.listdir(DATA_DIR):\n",
        "    data_transforms[f] = transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE),\n",
        "        transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "\n",
        "data_transforms['train'] = data_transforms['crop540']\n",
        "\n",
        "'''transforms.Compose([\n",
        "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])'''\n",
        "\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x),\n",
        "                                          transform)\n",
        "                  for x, transform in data_transforms.items()}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=8)\n",
        "              for x, dataset in image_datasets.items()}\n",
        "dataset_sizes = {x: len(dataset) for x, dataset in image_datasets.items()}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# make sure that we can store the model\n",
        "os.makedirs(STORAGE_DIR, exist_ok=True)\n",
        "print(STORAGE_DIR)\n",
        "\n",
        "def train_model(model: torch.nn.modules.Module, criterion, optimizer, \n",
        "                scheduler, num_epochs: int) -> Tuple[torch.nn.modules.Module, float]:\n",
        "    \"\"\"\n",
        "    Trains a pytorch Model for a certain number of epoch, stopping early if\n",
        "    no improvement was made in the last 10 epochs.\n",
        "\n",
        "    :return: The best model trained during the process (measured by the\n",
        "        validation accuracy) as well as it's accuracy on the validation set\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    impr_counter = 0\n",
        "    stop = False\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                impr_counter += 1\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    if INPUT_SIZE == 299 and phase == 'train':  # inception\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy and store the model\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "                impr_counter = 0\n",
        "                best_acc = epoch_acc\n",
        "                best_epoch = epoch\n",
        "                print('Storing')\n",
        "                torch.save(model, STORAGE_MODEL_TEMP)\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "            if impr_counter > 9:\n",
        "                print('No improvement in last 10 iterations; aborting')\n",
        "                stop = True\n",
        "\n",
        "        if stop:\n",
        "            break\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f} at epoch {}'.format(best_acc, best_epoch))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, best_acc\n",
        "\n",
        "\n",
        "def visualize_model(model: torch.nn.modules.Module, num_images=6):\n",
        "    \"\"\"\n",
        "    Visualises a pytorch model by showing it's results for validation\n",
        "    images.\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['validation']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "def get_confusion_matrix(model: torch.nn.modules.Module,\n",
        "                         data: str = 'validation') -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Retrieves the confusion matrix of a trained pytorch model instance for\n",
        "    the given data set.\n",
        "    \"\"\"\n",
        "    confusion_matrix = torch.zeros(NUM_CLASSES, NUM_CLASSES)\n",
        "    for i, (inputs, classes) in enumerate(dataloaders[data]):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "            confusion_matrix[t.long(), p.long()] += 1\n",
        "    return confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWHs5Uj-P18E",
        "colab_type": "text"
      },
      "source": [
        "4. # Declare unified classifier classes for the ResNet50, DenseNet161 and VGG16 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNR7hchCPpUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Using GPU: \", torch.cuda.is_available())\n",
        "\n",
        "\n",
        "class Model(ABC):\n",
        "    \"\"\"\n",
        "    Abstract class offering a unified interface for easily training various\n",
        "    different models requiring different setup steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, for_transfer_learning=True):\n",
        "        self._model = self._get_model()\n",
        "\n",
        "        if for_transfer_learning:\n",
        "            self.__setup_for_transfer()\n",
        "\n",
        "        self._setup_classifier()\n",
        "        self._model = self._model.to(device)\n",
        "\n",
        "        self.__optimizer = optim.SGD(self._model.parameters(), lr=0.0001,\n",
        "                               momentum=0.8)\n",
        "        self.__scheduler = lr_scheduler.StepLR(self.__optimizer,\n",
        "                                               step_size=5,\n",
        "                                               gamma=0.1)\n",
        "\n",
        "    def _get_model(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __setup_for_transfer(self):\n",
        "        for param in list(self._model.parameters())[:-1]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def _setup_classifier(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def optimize(self) -> float:\n",
        "        self._model = self._model.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        self._model, best_acc = train_model(self._model, criterion,\n",
        "                                            self.__optimizer, self.__scheduler,\n",
        "                                            num_epochs=1)\n",
        "        return best_acc\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self._model\n",
        "\n",
        "class VGG16(Model):\n",
        "\n",
        "    def _get_model(self):\n",
        "        return torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "    def _setup_classifier(self):\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, NUM_CLASSES),\n",
        "        )\n",
        "\n",
        "\n",
        "class ResNet50(Model):\n",
        "    def _get_model(self):\n",
        "        return torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "    def _setup_classifier(self):\n",
        "        nr_features = self._model.fc.in_features\n",
        "        self._model.fc = nn.Linear(nr_features, NUM_CLASSES)\n",
        "\n",
        "\n",
        "class DenseNet161(Model):\n",
        "    def _get_model(self):\n",
        "        return torchvision.models.densenet161(pretrained=True)\n",
        "\n",
        "    def _setup_classifier(self):\n",
        "        nr_features = self._model.classifier.in_features\n",
        "        self._model.classifier = nn.Linear(nr_features, NUM_CLASSES)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2--qJkTvXY1",
        "colab_type": "text"
      },
      "source": [
        "# 5 Declare utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpT6DnehvVOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best(model_cls=ResNet50, nr_repeats=10) -> torch.nn.modules.Module:\n",
        "    \"\"\"\n",
        "    Trains multiple instances of a certain model, storing the best instance\n",
        "    under STORAGE_MODEL\n",
        "\n",
        "    :param model_cls: The class used to instantiate model instances\n",
        "    :param nr_repeats: How often the the model is meant to be instantiated\n",
        "        and trained before picking the model with the highest accuracy\n",
        "    \"\"\"\n",
        "    best_acc = -1\n",
        "    best_model = None\n",
        "    for _ in range(nr_repeats):\n",
        "        model = model_cls(True)\n",
        "        acc = model.optimize()\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_model = model.model\n",
        "            torch.save(best_model, STORAGE_MODEL)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "\n",
        "def get_average_performance(model_cls: Type[Model], nr_repeats=10) -> float:\n",
        "    \"\"\"\n",
        "    Gets the average accuracy for a specific model type for a given number\n",
        "    of repeats.\n",
        "\n",
        "    :param model_cls: The class used to instantiate model instances\n",
        "    :param nr_repeats: How often the the model is meant to be instantiated,\n",
        "        trained and evaluated\n",
        "    \"\"\"\n",
        "    avg_acc = 0\n",
        "    for _ in range(nr_repeats):\n",
        "        model = model_cls(False)\n",
        "        avg_acc += model.optimize()\n",
        "    \n",
        "    return avg_acc / nr_repeats\n",
        "\n",
        "def get_average_confusion(model_cls: Type[Model], nr_repeats=10,\n",
        "                          dataset='validation') -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Instantiates and trains a specific model class before \n",
        "\n",
        "    :param model_cls: The class used to instantiate model instances\n",
        "    :param nr_repeats: How often the the model is meant to be instantiated,\n",
        "        trained and evaluated\n",
        "    :param dataset: The dataset to be used; should be a folder name found in\n",
        "        the DATA_DIR directory\n",
        "    :return: The average confusion matrix of dimension\n",
        "        NUM_CLASSES x NUM_CLASSES\n",
        "    \"\"\"\n",
        "    avg_acc = 0\n",
        "    avg_conf = torch.zeros(NUM_CLASSES, NUM_CLASSES)\n",
        "    for _ in range(nr_repeats):\n",
        "        model = model_cls(False)\n",
        "        acc = model.optimize()\n",
        "        conf = get_confusion_matrix(model.model, data=dataset)\n",
        "        print(acc, conf)\n",
        "        avg_conf += conf\n",
        "\n",
        "    return avg_conf / nr_repeats\n",
        "\n",
        "\n",
        "def get_test_confusion(model: torch.nn.modules.Module,\n",
        "                       exclude_prefix: str = 'crop') -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Evaluates an already trained pytorch model on the available training\n",
        "    data sets by acquiring the summated confusion matrix for all the test\n",
        "    data in the DATA_DIR directory.\n",
        "\n",
        "    :param model: The model meant to be evaluated\n",
        "    :param exclude_prefix: Prefix of datasets that are meant to be excluded\n",
        "        from the evaluation\n",
        "    \"\"\"\n",
        "    confs = []\n",
        "    for dataset in dataloaders:\n",
        "        if dataset.startswith(exclude_prefix) or dataset in ['train', 'validation']:\n",
        "            continue\n",
        "\n",
        "        confs.append(get_confusion_matrix(model, dataset))\n",
        "\n",
        "    return sum(confs)\n",
        "\n",
        "\n",
        "def get_test_f1(model: torch.nn.modules.Module,\n",
        "                exclude_prefix: str = 'crop') -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Evaluates an already trained pytorch model on the available training\n",
        "    data sets by acquiring the F1 scores for the individual classes for each for all individual test\n",
        "    data sets in the DATA_DIR directory.\n",
        "\n",
        "    :param model: The model meant to be evaluated\n",
        "    :param exclude_prefix: Prefix of datasets that are meant to be excluded\n",
        "        from the evaluation\n",
        "    :return: A matrix of shape NUM_CLASSES x <number of test sets>: each row features the F1-scores for a particular\n",
        "        test scenario\n",
        "    \"\"\"\n",
        "    f1_scores = []\n",
        "    confs = []\n",
        "    for dataset in dataloaders:\n",
        "        if dataset.startswith(exclude_prefix) or dataset in ['train', 'validation']:\n",
        "            continue\n",
        "\n",
        "        conf = get_confusion_matrix(model, dataset)\n",
        "        confs.append(copy.deepcopy(conf))\n",
        "        trans_conf = copy.deepcopy(conf.transpose(0, 1))\n",
        "\n",
        "        for i, row in enumerate(conf):\n",
        "            if any(list(row)):\n",
        "                row /= sum(row)\n",
        "        for i, row in enumerate(trans_conf):\n",
        "            if any(list(row)):\n",
        "                row /= sum(row)\n",
        "\n",
        "        recall = np.array(list(row[i] for i, row in enumerate(conf)))\n",
        "        precision = np.array(list(row[i] for i, row in enumerate(trans_conf)))\n",
        "        f1_scores.append(2 * recall * precision / precision + recall)\n",
        "\n",
        "    return np.array(f1_scores).transpose()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGVkIgiq7LYx",
        "colab_type": "text"
      },
      "source": [
        "# 6. Get best network from multiple tries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys8H3TPl7TXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_best(ResNet50, 10)\n",
        "print(get_test_f1(model))\n",
        "print(get_test_confusion(model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DG-wsUvPcnG",
        "colab_type": "text"
      },
      "source": [
        "# 7. Export Model to onnx format for integration in OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wdxfuRXSwr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(STORAGE_MODEL)\n",
        "dummy_input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE, device='cuda')\n",
        "torch.onnx.export(model, dummy_input,\n",
        "                  STORAGE_ONNX,\n",
        "                  opset_version=11)\n",
        "print('Finished')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}